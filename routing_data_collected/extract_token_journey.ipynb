{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Extract Token Journeys\n",
                "\n",
                "This notebook extracts individual token journeys from the routing data.\n",
                "\n",
                "**Steps:**\n",
                "1. Create output folders\n",
                "2. Extract token journeys from routing JSONL files"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Create Output Folders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.makedirs(\"humaneval_tokens\", exist_ok=True)\n",
                "os.makedirs(\"gsm8k_tokens\", exist_ok=True)\n",
                "print(\"Created folders: humaneval_tokens/, gsm8k_tokens/\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Define Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "# CONFIG: Set to None for ALL, or a number for first N\n",
                "MAX_PROBLEMS = None  # e.g., 10 for first 10 problems\n",
                "\n",
                "def get_problem_ids(filepath):\n",
                "    pids = set()\n",
                "    with open(filepath) as f:\n",
                "        for line in f:\n",
                "            if not line.strip(): continue\n",
                "            try: pids.add(json.loads(line)['problem_id'])\n",
                "            except: pass\n",
                "    return sorted(pids)\n",
                "\n",
                "def get_max_token(filepath, problem_id):\n",
                "    max_tok = 0\n",
                "    with open(filepath) as f:\n",
                "        for line in f:\n",
                "            if not line.strip(): continue\n",
                "            try:\n",
                "                d = json.loads(line)\n",
                "                if d['problem_id'] == problem_id:\n",
                "                    max_tok = max(max_tok, d['token_idx'])\n",
                "            except: pass\n",
                "    return max_tok + 1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Extract HumanEval Token Journeys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "humaneval_file = \"humaneval_full_routing.jsonl\"\n",
                "problem_ids = get_problem_ids(humaneval_file)[:MAX_PROBLEMS]\n",
                "print(f\"Extracting {len(problem_ids)} problems...\")\n",
                "\n",
                "for pid in problem_ids:\n",
                "    max_tok = get_max_token(humaneval_file, pid)\n",
                "    print(f\"  Problem {pid}: {max_tok} tokens\")\n",
                "    !python extract_tokens.py {humaneval_file} --problem {pid} --tokens 0 {max_tok} --output-dir humaneval_tokens"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Extract GSM8K Token Journeys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gsm8k_file = \"gsm8k_full_routing.jsonl\"\n",
                "problem_ids = get_problem_ids(gsm8k_file)[:MAX_PROBLEMS]\n",
                "print(f\"Extracting {len(problem_ids)} problems...\")\n",
                "\n",
                "for pid in problem_ids:\n",
                "    max_tok = get_max_token(gsm8k_file, pid)\n",
                "    print(f\"  Problem {pid}: {max_tok} tokens\")\n",
                "    !python extract_tokens.py {gsm8k_file} --problem {pid} --tokens 0 {max_tok} --output-dir gsm8k_tokens"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Verify Extraction (Stats)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "from collections import defaultdict\n",
                "\n",
                "def print_folder_stats(dataset_name):\n",
                "    folder = f\"{dataset_name}_tokens\"\n",
                "    files = glob.glob(f\"{folder}/p*_token_*.jsonl\")\n",
                "    \n",
                "    if not files:\n",
                "        print(f\"Dataset: {dataset_name} -> NO FILES FOUND in {folder}/\")\n",
                "        return\n",
                "        \n",
                "    problems = defaultdict(list)\n",
                "    for f in files:\n",
                "        basename = f.split('/')[-1]\n",
                "        pid = int(basename.split('_token_')[0][1:])\n",
                "        tok = int(basename.split('_token_')[1].split('.')[0])\n",
                "        problems[pid].append(tok)\n",
                "    \n",
                "    total_tokens = sum(len(toks) for toks in problems.values())\n",
                "    avg_tokens = total_tokens / len(problems)\n",
                "    \n",
                "    print(f\"Dataset: {dataset_name}\")\n",
                "    print(f\"  Total Problems: {len(problems)}\")\n",
                "    print(f\"  Total Tokens:   {total_tokens}\")\n",
                "    print(f\"  Avg Tokens/Prob: {avg_tokens:.1f}\")\n",
                "    print(\"-\" * 40)\n",
                "\n",
                "print_folder_stats(\"humaneval\")\n",
                "print_folder_stats(\"gsm8k\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}